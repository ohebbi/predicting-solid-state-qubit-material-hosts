{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-Supervised learning \n",
    "\n",
    "In this notebook we will train a model based on the previous 4 notebooks. This include the use of two supervised classifiers named RandomForest and Gradient Boost. We will be using the library of scikitlearn to do this. However, there is no limitation in number of algorithms that can be used, since the notebook has been made modular for further easy implementations of other machine learning algorithms. \n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- Imports \n",
    "- Algorithms\n",
    "- Dataset analysis\n",
    "    - How do we evaluate the model?\n",
    "    - Optimal hyperparameter search \n",
    "- Running the different algorithms\n",
    "- Visualizing the cross-validated trained models\n",
    "    - Interpreting important features used by the models\n",
    "    - Precision and recall metrics\n",
    "- Predicting solid-state qubit candidates\n",
    "    - Save the summary and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "#OPTIONAL: Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data directory /Users/ohebbi/Documents/UiO/Masterprosjekt/predicting-solid-state-qubit-candidates/data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from pathlib import Path\n",
    "data_dir = Path.cwd().parent.parent / \"data\"\n",
    "models_dir = Path.cwd().parent.parent / \"models\" \n",
    "\n",
    "print(\"Current data directory {}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import train_model, predict_model\n",
    "from src.features import build_features\n",
    "from src.visualization import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# CV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "#visualizations\n",
    "import plotly.graph_objs as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "# setting random seed for reproducibility\n",
    "random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertApproach = \"01-naive-approach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>full_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mp-7</td>\n",
       "      <td>12.036711</td>\n",
       "      <td>13.274013</td>\n",
       "      <td>-1.737915</td>\n",
       "      <td>14.739557</td>\n",
       "      <td>-0.757618</td>\n",
       "      <td>2.116654</td>\n",
       "      <td>4.575873</td>\n",
       "      <td>6.906179</td>\n",
       "      <td>-9.019853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548943</td>\n",
       "      <td>-0.465928</td>\n",
       "      <td>-0.473137</td>\n",
       "      <td>0.890753</td>\n",
       "      <td>0.310688</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>1.431401</td>\n",
       "      <td>0.098227</td>\n",
       "      <td>-1.873022</td>\n",
       "      <td>S6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp-14</td>\n",
       "      <td>8.736943</td>\n",
       "      <td>20.045744</td>\n",
       "      <td>-2.790344</td>\n",
       "      <td>14.690083</td>\n",
       "      <td>-0.933481</td>\n",
       "      <td>2.083661</td>\n",
       "      <td>1.902692</td>\n",
       "      <td>8.221801</td>\n",
       "      <td>-7.243127</td>\n",
       "      <td>...</td>\n",
       "      <td>2.015923</td>\n",
       "      <td>0.556497</td>\n",
       "      <td>-2.521934</td>\n",
       "      <td>0.882494</td>\n",
       "      <td>1.243217</td>\n",
       "      <td>1.420091</td>\n",
       "      <td>0.882175</td>\n",
       "      <td>-0.500076</td>\n",
       "      <td>2.041902</td>\n",
       "      <td>Se3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mp-19</td>\n",
       "      <td>6.181269</td>\n",
       "      <td>24.478638</td>\n",
       "      <td>-2.364966</td>\n",
       "      <td>17.295379</td>\n",
       "      <td>-0.855960</td>\n",
       "      <td>2.761114</td>\n",
       "      <td>-1.215268</td>\n",
       "      <td>7.243134</td>\n",
       "      <td>-6.281066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544680</td>\n",
       "      <td>-0.755902</td>\n",
       "      <td>-2.107227</td>\n",
       "      <td>0.647835</td>\n",
       "      <td>0.111707</td>\n",
       "      <td>0.223679</td>\n",
       "      <td>0.048232</td>\n",
       "      <td>0.795670</td>\n",
       "      <td>2.164651</td>\n",
       "      <td>Te3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mp-24</td>\n",
       "      <td>14.674316</td>\n",
       "      <td>7.454499</td>\n",
       "      <td>-15.765739</td>\n",
       "      <td>0.837589</td>\n",
       "      <td>-20.045318</td>\n",
       "      <td>4.477661</td>\n",
       "      <td>-3.367162</td>\n",
       "      <td>13.167061</td>\n",
       "      <td>-1.210036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609341</td>\n",
       "      <td>-0.939367</td>\n",
       "      <td>1.314977</td>\n",
       "      <td>1.194233</td>\n",
       "      <td>-0.931539</td>\n",
       "      <td>1.427012</td>\n",
       "      <td>-1.127582</td>\n",
       "      <td>-1.547011</td>\n",
       "      <td>4.853501</td>\n",
       "      <td>C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mp-47</td>\n",
       "      <td>15.181173</td>\n",
       "      <td>6.474877</td>\n",
       "      <td>-14.494483</td>\n",
       "      <td>3.266178</td>\n",
       "      <td>-20.365175</td>\n",
       "      <td>5.399835</td>\n",
       "      <td>-3.528550</td>\n",
       "      <td>12.751007</td>\n",
       "      <td>-4.161845</td>\n",
       "      <td>...</td>\n",
       "      <td>1.832248</td>\n",
       "      <td>3.006065</td>\n",
       "      <td>2.845476</td>\n",
       "      <td>-0.502321</td>\n",
       "      <td>-0.016508</td>\n",
       "      <td>-0.393536</td>\n",
       "      <td>-1.549406</td>\n",
       "      <td>-1.542916</td>\n",
       "      <td>1.261254</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>mp-1205479</td>\n",
       "      <td>6.206636</td>\n",
       "      <td>5.719011</td>\n",
       "      <td>7.759523</td>\n",
       "      <td>-6.362579</td>\n",
       "      <td>-0.826076</td>\n",
       "      <td>0.676745</td>\n",
       "      <td>-2.438982</td>\n",
       "      <td>-8.286891</td>\n",
       "      <td>-2.392091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417694</td>\n",
       "      <td>0.558660</td>\n",
       "      <td>-1.414721</td>\n",
       "      <td>-0.934363</td>\n",
       "      <td>0.889854</td>\n",
       "      <td>-0.123628</td>\n",
       "      <td>-0.734332</td>\n",
       "      <td>-0.684701</td>\n",
       "      <td>0.499590</td>\n",
       "      <td>K44Sb22F110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>mp-1208643</td>\n",
       "      <td>5.607075</td>\n",
       "      <td>15.004247</td>\n",
       "      <td>-3.672193</td>\n",
       "      <td>-2.746463</td>\n",
       "      <td>1.467341</td>\n",
       "      <td>-1.668852</td>\n",
       "      <td>1.622773</td>\n",
       "      <td>-1.581471</td>\n",
       "      <td>4.301946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518502</td>\n",
       "      <td>0.612865</td>\n",
       "      <td>-0.650554</td>\n",
       "      <td>-0.571037</td>\n",
       "      <td>-0.211232</td>\n",
       "      <td>-0.207200</td>\n",
       "      <td>-1.548408</td>\n",
       "      <td>1.267779</td>\n",
       "      <td>0.214643</td>\n",
       "      <td>Sr4Hf4S12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>mp-1210722</td>\n",
       "      <td>11.166933</td>\n",
       "      <td>4.146045</td>\n",
       "      <td>-3.790303</td>\n",
       "      <td>-4.441722</td>\n",
       "      <td>2.609776</td>\n",
       "      <td>-0.237385</td>\n",
       "      <td>-0.088705</td>\n",
       "      <td>-0.837357</td>\n",
       "      <td>-0.141340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129974</td>\n",
       "      <td>-0.646658</td>\n",
       "      <td>0.302142</td>\n",
       "      <td>-0.362812</td>\n",
       "      <td>-0.783819</td>\n",
       "      <td>-0.700142</td>\n",
       "      <td>-0.822052</td>\n",
       "      <td>0.446219</td>\n",
       "      <td>0.427608</td>\n",
       "      <td>Mg2Te2Mo2O12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>mp-1232407</td>\n",
       "      <td>18.535289</td>\n",
       "      <td>-12.749979</td>\n",
       "      <td>-0.516893</td>\n",
       "      <td>4.748835</td>\n",
       "      <td>-9.039990</td>\n",
       "      <td>1.098921</td>\n",
       "      <td>-1.610940</td>\n",
       "      <td>-0.817673</td>\n",
       "      <td>0.619768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971382</td>\n",
       "      <td>0.589894</td>\n",
       "      <td>-0.215145</td>\n",
       "      <td>0.288490</td>\n",
       "      <td>-0.049993</td>\n",
       "      <td>0.126361</td>\n",
       "      <td>0.397961</td>\n",
       "      <td>-0.042026</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>Li6B6H32N4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>mp-1238445</td>\n",
       "      <td>19.154867</td>\n",
       "      <td>-14.554489</td>\n",
       "      <td>-1.179011</td>\n",
       "      <td>0.042510</td>\n",
       "      <td>-9.393463</td>\n",
       "      <td>0.558854</td>\n",
       "      <td>-5.028681</td>\n",
       "      <td>-0.888533</td>\n",
       "      <td>1.647022</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095957</td>\n",
       "      <td>-0.529111</td>\n",
       "      <td>0.722857</td>\n",
       "      <td>-0.941878</td>\n",
       "      <td>-0.952193</td>\n",
       "      <td>1.604622</td>\n",
       "      <td>-0.194916</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>-0.726762</td>\n",
       "      <td>Be8H64N16F32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1618 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     material_id          0          1          2          3          4  \\\n",
       "0           mp-7  12.036711  13.274013  -1.737915  14.739557  -0.757618   \n",
       "1          mp-14   8.736943  20.045744  -2.790344  14.690083  -0.933481   \n",
       "2          mp-19   6.181269  24.478638  -2.364966  17.295379  -0.855960   \n",
       "3          mp-24  14.674316   7.454499 -15.765739   0.837589 -20.045318   \n",
       "4          mp-47  15.181173   6.474877 -14.494483   3.266178 -20.365175   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1613  mp-1205479   6.206636   5.719011   7.759523  -6.362579  -0.826076   \n",
       "1614  mp-1208643   5.607075  15.004247  -3.672193  -2.746463   1.467341   \n",
       "1615  mp-1210722  11.166933   4.146045  -3.790303  -4.441722   2.609776   \n",
       "1616  mp-1232407  18.535289 -12.749979  -0.516893   4.748835  -9.039990   \n",
       "1617  mp-1238445  19.154867 -14.554489  -1.179011   0.042510  -9.393463   \n",
       "\n",
       "             5         6          7         8  ...       246       247  \\\n",
       "0     2.116654  4.575873   6.906179 -9.019853  ...  0.548943 -0.465928   \n",
       "1     2.083661  1.902692   8.221801 -7.243127  ...  2.015923  0.556497   \n",
       "2     2.761114 -1.215268   7.243134 -6.281066  ...  0.544680 -0.755902   \n",
       "3     4.477661 -3.367162  13.167061 -1.210036  ...  1.609341 -0.939367   \n",
       "4     5.399835 -3.528550  12.751007 -4.161845  ...  1.832248  3.006065   \n",
       "...        ...       ...        ...       ...  ...       ...       ...   \n",
       "1613  0.676745 -2.438982  -8.286891 -2.392091  ...  0.417694  0.558660   \n",
       "1614 -1.668852  1.622773  -1.581471  4.301946  ... -0.518502  0.612865   \n",
       "1615 -0.237385 -0.088705  -0.837357 -0.141340  ...  0.129974 -0.646658   \n",
       "1616  1.098921 -1.610940  -0.817673  0.619768  ... -0.971382  0.589894   \n",
       "1617  0.558854 -5.028681  -0.888533  1.647022  ... -1.095957 -0.529111   \n",
       "\n",
       "           248       249       250       251       252       253       254  \\\n",
       "0    -0.473137  0.890753  0.310688  0.007499  1.431401  0.098227 -1.873022   \n",
       "1    -2.521934  0.882494  1.243217  1.420091  0.882175 -0.500076  2.041902   \n",
       "2    -2.107227  0.647835  0.111707  0.223679  0.048232  0.795670  2.164651   \n",
       "3     1.314977  1.194233 -0.931539  1.427012 -1.127582 -1.547011  4.853501   \n",
       "4     2.845476 -0.502321 -0.016508 -0.393536 -1.549406 -1.542916  1.261254   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1613 -1.414721 -0.934363  0.889854 -0.123628 -0.734332 -0.684701  0.499590   \n",
       "1614 -0.650554 -0.571037 -0.211232 -0.207200 -1.548408  1.267779  0.214643   \n",
       "1615  0.302142 -0.362812 -0.783819 -0.700142 -0.822052  0.446219  0.427608   \n",
       "1616 -0.215145  0.288490 -0.049993  0.126361  0.397961 -0.042026  0.025693   \n",
       "1617  0.722857 -0.941878 -0.952193  1.604622 -0.194916  0.178947 -0.726762   \n",
       "\n",
       "      full_formula  \n",
       "0               S6  \n",
       "1              Se3  \n",
       "2              Te3  \n",
       "3               C8  \n",
       "4               C4  \n",
       "...            ...  \n",
       "1613   K44Sb22F110  \n",
       "1614     Sr4Hf4S12  \n",
       "1615  Mg2Te2Mo2O12  \n",
       "1616    Li6B6H32N4  \n",
       "1617  Be8H64N16F32  \n",
       "\n",
       "[1618 rows x 257 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData   = pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"trainingData.pkl\")\n",
    "trainingTarget= pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"trainingTarget.pkl\")\n",
    "testSet       = pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"testSet.pkl\")\n",
    "\n",
    "trainingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "Below we define the algorithm to use and its abbreviation. Parameters that are optional to tune are the parameters to the algorithms, with the default value as their optimised value. Another parameter to tune is how many cross-validations one wants to iterate through for the analysis. In addition, one has to find the best features for a new algorithm which will be added further down in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertAlgorithms    = [RandomForestClassifier    (random_state=random_state),\\\n",
    "                       GradientBoostingClassifier(random_state=random_state)]\n",
    "InsertAbbreviations = [\"RF\", \"GB\"]\n",
    "InsertprettyNames   = [\"Random Forest\", \"Gradient Boost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis\n",
    "\n",
    "\n",
    "## How do we evaluate the model?\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. \n",
    "\n",
    "### k-fold cross-validation\n",
    "\n",
    "In k-fold cross-validation, the sample is partioned into k equal sized subsamples. Of the k samples, a single sample is used as validation set while the remaining k-1 samples are used as training data. The process is then repeated k-times, such that each of the k-th subsample is used as validation set exactly one time. Therefore, all observations are used for both training and validation, and each observation is used for validation exactly once. The k results from the folds can then be averaged to produce an estimate.\n",
    "\n",
    "### Stratified k-fold cross-validation\n",
    "\n",
    "In stratified k-fold cross validation, the fold that is selected contains roughly the same proportions of existing class labels. \n",
    "\n",
    "### n-repeated stratified k-fold cross-validation\n",
    "\n",
    "In n-repeated stratified k-fold cross-validation, the stratified k-fold cross-validation is repeated n times, which yields n random partitions of the original sample. The n results can be averaged to produce a single estimation. \n",
    "\n",
    "## Sample size\n",
    "To not discrimate a class, we make sure that each class is equally represented in the subsamples. Underneath shows a brief overview of the different methods involved to deal with this challenge.\n",
    "\n",
    "### Random oversampling of minority class\n",
    "\n",
    "Random oversampling can be achived by randomly duplicating examples from the minority class and adding them to the training dataset. \n",
    "\n",
    "The approach can be effective to algorithms that are vulnerable to a skewed dsitribution, however, it can also affect algorithms to overfit the minority class. \n",
    "\n",
    "### Random Undersampling of majority class\n",
    "\n",
    "Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset. \n",
    "\n",
    "This can prove problematic, since the loss of data can make the decision boundary between minority and majority instances harder to learn. Additionally, there is a chance that the model might loose valuable information. \n",
    "\n",
    "### Both oversampling and undersampling\n",
    "\n",
    "A third option might be to combine the two of them. \n",
    "\n",
    "\n",
    "## Optimal hyperparameters search\n",
    "\n",
    "In this section we will find the optimal parameters used for the various algorithms. We will use imblearn's Pipeline and its implemented samplers, such as SMOTE and RandomUnderSampler. The advantage of using imblearn instead of sklearn, is that sklearn's pipeline will fit the samplers to the validation data as well, while imblearn only fit the resamplers to the training data. We store the best estimators and use them again under this section.\n",
    "\n",
    "It is possible to have a large search over a wide amount of properties, but that is indeed extremely cpu-demanding. Therefore, we restrict ourself to the standard choice of some properties, but include a search for properties that can reduce the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberRuns=10\n",
    "numberSplits = 10\n",
    "\n",
    "includeSampleMethods = [\"\", \"under\", \"over\", \"both\"]\n",
    "\n",
    "rskfold = RepeatedStratifiedKFold(n_splits=numberSplits, n_repeats=numberRuns, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best params for: RF \n",
      "Fitting 100 folds for each of 72 candidates, totalling 7200 fits\n",
      "Pipeline(steps=[('model',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=8,\n",
      "                                        n_estimators=10, random_state=1))])\n",
      "Finding best params for: RF under\n",
      "Fitting 100 folds for each of 72 candidates, totalling 7200 fits\n",
      "Pipeline(steps=[('underSampler',\n",
      "                 RandomUnderSampler(sampling_strategy='majority')),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='log2',\n",
      "                                        n_estimators=1000, random_state=1))])\n",
      "Finding best params for: RF over\n",
      "Fitting 100 folds for each of 72 candidates, totalling 7200 fits\n",
      "Pipeline(steps=[('overSampler', SMOTE(sampling_strategy='minority')),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=8, max_features='sqrt',\n",
      "                                        n_estimators=1000, random_state=1))])\n",
      "Finding best params for: RF both\n",
      "Fitting 100 folds for each of 72 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [12:52:55, 46375.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('overSampler', SMOTE(sampling_strategy='minority')),\n",
      "                ('underSampler',\n",
      "                 RandomUnderSampler(sampling_strategy='majority')),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=8, n_estimators=1000,\n",
      "                                        random_state=1))])\n",
      "Finding best params for: GB \n",
      "Fitting 100 folds for each of 96 candidates, totalling 9600 fits\n"
     ]
    }
   ],
   "source": [
    "ModelsBestParams = pd.Series({}, dtype=\"string\")\n",
    "\n",
    "Abbreviations = []\n",
    "prettyNames   = []\n",
    "Algorithms = []\n",
    "\n",
    "for i, algorithm in tqdm(enumerate(InsertAlgorithms)):\n",
    "    for method in includeSampleMethods:\n",
    "        print(\"Finding best params for: {}\".format(InsertAbbreviations[i] + \" \" + method))\n",
    "        bestEstimator, ModelsBestParams[InsertAbbreviations[i] + \" \" + method] = train_model.applyGridSearch(\n",
    "                                                                             X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                                                             y = trainingTarget.values.reshape(-1,),\n",
    "                                                                        model = algorithm, \n",
    "                                                                           cv = rskfold, \n",
    "                                                                 sampleMethod = method)\n",
    "        Abbreviations.append(InsertAbbreviations[i] + \" \" + method)\n",
    "        prettyNames.append(InsertAbbreviations[i] + \" \" + method)\n",
    "        Algorithms.append(bestEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ModelsBestParams[\"RF \"].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the best estimators\n",
    "## Accuracy and f1-score\n",
    "Under follows the general model runSupervisedModel that takes the as parameter which model to run and returns nice statistics formatted as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SupervisedModels = pd.Series({}, dtype=\"string\")\n",
    "\n",
    "for i, algorithm in enumerate(Algorithms): \n",
    "    print(\"Current training algorithm: {}\".format(prettyNames[i]))\n",
    "    SupervisedModels[Abbreviations[i]] = (\n",
    "        train_model.runSupervisedModel(classifier  = algorithm, \n",
    "                                     X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                     y = trainingTarget.values.reshape(-1,),\n",
    "                                     k = numberSplits,\n",
    "                                     n = numberRuns,\n",
    "                                    cv = rskf,\n",
    "                     featureImportance = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the cross-validated trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_accuracy(SupervisedModels, prettyNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is calculated as a function difference of the $100$ models in the purpose of visalizing how much the models deviate from each other.\n",
    "\n",
    "## Interpreting important features used by the models\n",
    "\n",
    "Which features are the most important in predicting to give a label $0$ or $1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def plot_important_features(models, names):\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text='Features used in model (Nruns = {})'.format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title=\"Number times\"),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        fig.add_traces(go.Bar(name=names[i], x=trainingData.columns.values, y=model['importantKeys']))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text=\"Feature Importance for the 100th iteration\".format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title='Relative importance'),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        fig.add_traces(go.Bar(name=names[i], x=trainingData.columns.values, y=model['relativeImportance']))\n",
    "\n",
    "    fig.show()\n",
    "\"\"\"\n",
    "#visualize.plot_important_features(SupervisedModels, prettyNames, \n",
    "#                        X=trainingData.drop([\"material_id\", \"full_formula\"], axis=1),\n",
    "#                       k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize.plot_important_features_restricted_domain(SupervisedModels, prettyNames, trainingData, k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_confusion_metrics(SupervisedModels, prettyNames, trainingData, k = numberSplits, n = numberRuns, abbreviations=prettyNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize.plot_confusion_matrixQT(SupervisedModels, trainingTarget, trainingData, names=prettyNames, k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize.confusion_matrixQT(SupervisedModels, trainingTarget, prettyNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, algorithm in enumerate(Algorithms): \n",
    "    print(\"Current training algorithm: {}\".format(prettyNames[i]))\n",
    "    visualize.draw_cv_roc_curve(classifier  = algorithm, \n",
    "                                     X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                     y = trainingTarget.values.reshape(-1,),\n",
    "                                     k = numberSplits,\n",
    "                                     n = numberRuns,\n",
    "                                    cv = rskf,\n",
    "                     featureImportance = True)\n",
    "#draw_cv_roc_curve(clf, cv, X, y, title='Cross Validated ROC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, algorithm in enumerate(Algorithms): \n",
    "    print(\"Current training algorithm: {}\".format(prettyNames[i]))\n",
    "        visualize.draw_cv_pr_curve(classifier  = algorithm, \n",
    "                                     X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                     y = trainingTarget.values.reshape(-1,),\n",
    "                                     k = numberSplits,\n",
    "                                     n = numberRuns,\n",
    "                                    cv = rskf,\n",
    "                     featureImportance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting solid-state qubit candidates\n",
    "\n",
    "It is time to make the prediction based on the best estimators and features possible. We have chosen to choose the features that have been deemed important by sklearn at least 50 percent of the cross validation runs as important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary                 = pd.DataFrame({}, dtype=\"string\")\n",
    "Summary[\"material_id\"]  = testSet[\"material_id\"]\n",
    "Summary[\"full_formula\"] = testSet[\"full_formula\"]\n",
    "Summary[\"pretty_formula\"] = testSet[\"pretty_formula\"]\n",
    "\n",
    "PredictedCandidates = pd.Series({}, dtype=\"string\")\n",
    "\n",
    "threshold = numberSplits*numberRuns/2 #50% when equal\n",
    "trainSet = trainingData.drop([\"material_id\", \"full_formula\"], axis=1)\n",
    "testData = testSet.drop([\"pretty_formula\", \"candidate\", \"full_formula\", \"material_id\"], axis=1)\n",
    "fittedAlgorithms = [] \n",
    "\n",
    "for i, algorithm in tqdm(enumerate(Algorithms)):\n",
    "    \n",
    "    fittedAlgorithm = train_model.fitAlgorithm(algorithm, \n",
    "                                    trainingData   = trainSet[trainSet.columns[SupervisedModels[Abbreviations[i]][\"importantKeys\"]>threshold]],\\\n",
    "                                    trainingTarget = trainingTarget.values.reshape(-1,),)\n",
    "    \n",
    "    fittedAlgorithms.append(fittedAlgorithm)\n",
    "    \n",
    "    PredictedCandidates[Abbreviations[i]],\\\n",
    "    PredictedCandidates[Abbreviations[i]+\"Prob\"] = predict_model.runPredictions(fittedAlgorithm,\\\n",
    "                                                        testData = testData[testData.columns[SupervisedModels[Abbreviations[i]][\"importantKeys\"]>threshold]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abbreviation in Abbreviations:\n",
    "    Summary[abbreviation]            = PredictedCandidates[abbreviation]\n",
    "    Summary[abbreviation + \"Prob\"]       = PredictedCandidates[abbreviation + \"Prob\"]\n",
    "    print(\"{} predict the number of candidates as: {}\".format(abbreviation, int(np.sum(PredictedCandidates[abbreviation]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the summary and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fitted_algorithm in tqdm(enumerate(fittedAlgorithms)):\n",
    "    file_path = Path(models_dir / InsertApproach / \"trained-models\" / Path(prettyNames[i] + \".pkl\"))\n",
    "    with file_path.open(\"wb\") as fp:\n",
    "        pickle.dump(fitted_algorithm, fp)\n",
    "        \n",
    "\n",
    "Summary.to_pickle(models_dir / InsertApproach / \"summary\" / \"summary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score,precision_score, recall_score, make_scorer\n",
    "\n",
    "scoring = {'accuracy':  make_scorer(accuracy_score),\n",
    "               'precision': make_scorer(precision_score),\n",
    "               'recall':    make_scorer(recall_score),\n",
    "               'f1':        make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(ModelsBestParams[i].best_estimator_.named_steps[\"model\"].feature_importances_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_df(ModelsBestParams[0],list(trainingData.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "features=list(trainingData.columns[ModelsBestParams[0].best_estimator_.named_steps[\"model\"].support_])\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = ModelsBestParams[0].cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
    "          fontsize=16)\n",
    "\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0, 202)\n",
    "ax.set_ylim(0.73, 1)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results['param_model__n_estimators'].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), ['g', 'k', 'r', 'b']):\n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score,\n",
    "                (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
