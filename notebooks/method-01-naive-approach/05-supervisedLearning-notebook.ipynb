{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-Supervised learning \n",
    "\n",
    "In this notebook we will train a model based on the previous 4 notebooks. This include the use of two supervised classifiers named RandomForest and Gradient Boost. We will be using the library of scikitlearn to do this. However, there is no limitation in number of algorithms that can be used, since the notebook has been made modular for further easy implementations of other machine learning algorithms. \n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- Imports \n",
    "- Algorithms\n",
    "- Dataset analysis\n",
    "    - How do we evaluate the model?\n",
    "    - Optimal hyperparameter search \n",
    "- Running the different algorithms\n",
    "- Visualizing the cross-validated trained models\n",
    "    - Interpreting important features used by the models\n",
    "    - Precision and recall metrics\n",
    "- Predicting solid-state qubit candidates\n",
    "    - Save the summary and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "#OPTIONAL: Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data directory /home/oliver/Dokumenter/masterprosjekt/predicting-solid-state-qubit-candidates/data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from pathlib import Path\n",
    "data_dir = Path.cwd().parent.parent / \"data\"\n",
    "models_dir = Path.cwd().parent.parent / \"models\" \n",
    "\n",
    "print(\"Current data directory {}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use the ChemEnv tool for your research, please consider citing the following reference(s) :\n",
      "==================================================================================================\n",
      "David Waroquiers, Xavier Gonze, Gian-Marco Rignanese, Cathrin Welker-Nieuwoudt, Frank Rosowski,\n",
      "Michael Goebel, Stephan Schenk, Peter Degelmann, Rute Andre, Robert Glaum, and Geoffroy Hautier,\n",
      "\"Statistical analysis of coordination environments in oxides\",\n",
      "Chem. Mater., 2017, 29 (19), pp 8346-8360,\n",
      "DOI: 10.1021/acs.chemmater.7b02766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import train_model, predict_model\n",
    "from src.features import build_features\n",
    "from src.visualization import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Feature selections\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "#metrics and nice visualization\n",
    "from tqdm import tqdm\n",
    "\n",
    "#visualizations\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# setting random seed for reproducibility\n",
    "random_state=23462478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertApproach = \"01-naive-approach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_id</th>\n",
       "      <th>AtomicOrbitals|HOMO_character</th>\n",
       "      <th>AtomicOrbitals|HOMO_element</th>\n",
       "      <th>AtomicOrbitals|HOMO_energy</th>\n",
       "      <th>AtomicOrbitals|LUMO_character</th>\n",
       "      <th>AtomicOrbitals|LUMO_element</th>\n",
       "      <th>AtomicOrbitals|LUMO_energy</th>\n",
       "      <th>AtomicOrbitals|gap_AO</th>\n",
       "      <th>AtomicPackingEfficiency|mean simul. packing efficiency</th>\n",
       "      <th>AtomicPackingEfficiency|mean abs simul. packing efficiency</th>\n",
       "      <th>...</th>\n",
       "      <th>OxidationStates|std_dev oxidation state</th>\n",
       "      <th>MP_Eg</th>\n",
       "      <th>OQMD_Eg</th>\n",
       "      <th>AFLOW_Eg</th>\n",
       "      <th>AFLOW-fitted_Eg</th>\n",
       "      <th>AFLOWML_Eg</th>\n",
       "      <th>JARVIS-TBMBJ_Eg</th>\n",
       "      <th>JARVIS-OPT_Eg</th>\n",
       "      <th>Exp_Eg</th>\n",
       "      <th>spillage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mp-7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.261676</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.261676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4881</td>\n",
       "      <td>2.085</td>\n",
       "      <td>2.5251</td>\n",
       "      <td>4.31683</td>\n",
       "      <td>2.490</td>\n",
       "      <td>3.0448</td>\n",
       "      <td>1.9604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.245806</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.245806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0119</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>2.23188</td>\n",
       "      <td>0.997</td>\n",
       "      <td>2.2888</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mp-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.226594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.226594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5752</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>1.11978</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mp-24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.4528</td>\n",
       "      <td>4.21937</td>\n",
       "      <td>3.355</td>\n",
       "      <td>3.3186</td>\n",
       "      <td>2.7427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mp-47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.199186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3395</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.3412</td>\n",
       "      <td>5.41694</td>\n",
       "      <td>3.166</td>\n",
       "      <td>4.7622</td>\n",
       "      <td>3.7645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>mp-1205479</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.415606</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.185623</td>\n",
       "      <td>0.229983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7325</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.468</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>mp-1208643</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.261676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>-0.166465</td>\n",
       "      <td>0.095211</td>\n",
       "      <td>-0.033747</td>\n",
       "      <td>0.037006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0461</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>mp-1210722</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.338381</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.226594</td>\n",
       "      <td>0.111787</td>\n",
       "      <td>-0.007146</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.872</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>mp-1232407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.233471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.233471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.359</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>mp-1238445</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.266297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.233471</td>\n",
       "      <td>0.032826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.344</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1618 rows Ã— 3482 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     material_id  AtomicOrbitals|HOMO_character  AtomicOrbitals|HOMO_element  \\\n",
       "0           mp-7                            2.0                           16   \n",
       "1          mp-14                            2.0                           34   \n",
       "2          mp-19                            2.0                           52   \n",
       "3          mp-24                            2.0                            6   \n",
       "4          mp-47                            2.0                            6   \n",
       "...          ...                            ...                          ...   \n",
       "1613  mp-1205479                            2.0                            9   \n",
       "1614  mp-1208643                            2.0                           16   \n",
       "1615  mp-1210722                            2.0                            8   \n",
       "1616  mp-1232407                            1.0                            1   \n",
       "1617  mp-1238445                            2.0                            7   \n",
       "\n",
       "      AtomicOrbitals|HOMO_energy  AtomicOrbitals|LUMO_character  \\\n",
       "0                      -0.261676                            2.0   \n",
       "1                      -0.245806                            2.0   \n",
       "2                      -0.226594                            2.0   \n",
       "3                      -0.199186                            2.0   \n",
       "4                      -0.199186                            2.0   \n",
       "...                          ...                            ...   \n",
       "1613                   -0.415606                            2.0   \n",
       "1614                   -0.261676                            1.0   \n",
       "1615                   -0.338381                            2.0   \n",
       "1616                   -0.233471                            1.0   \n",
       "1617                   -0.266297                            1.0   \n",
       "\n",
       "      AtomicOrbitals|LUMO_element  AtomicOrbitals|LUMO_energy  \\\n",
       "0                              16                   -0.261676   \n",
       "1                              34                   -0.245806   \n",
       "2                              52                   -0.226594   \n",
       "3                               6                   -0.199186   \n",
       "4                               6                   -0.199186   \n",
       "...                           ...                         ...   \n",
       "1613                           51                   -0.185623   \n",
       "1614                           72                   -0.166465   \n",
       "1615                           52                   -0.226594   \n",
       "1616                            1                   -0.233471   \n",
       "1617                            1                   -0.233471   \n",
       "\n",
       "      AtomicOrbitals|gap_AO  \\\n",
       "0                  0.000000   \n",
       "1                  0.000000   \n",
       "2                  0.000000   \n",
       "3                  0.000000   \n",
       "4                  0.000000   \n",
       "...                     ...   \n",
       "1613               0.229983   \n",
       "1614               0.095211   \n",
       "1615               0.111787   \n",
       "1616               0.000000   \n",
       "1617               0.032826   \n",
       "\n",
       "      AtomicPackingEfficiency|mean simul. packing efficiency  \\\n",
       "0                                              0.023994        \n",
       "1                                              0.023994        \n",
       "2                                              0.023994        \n",
       "3                                              0.023994        \n",
       "4                                              0.023994        \n",
       "...                                                 ...        \n",
       "1613                                           0.000000        \n",
       "1614                                          -0.033747        \n",
       "1615                                          -0.007146        \n",
       "1616                                           0.000000        \n",
       "1617                                           0.000000        \n",
       "\n",
       "      AtomicPackingEfficiency|mean abs simul. packing efficiency  ...  \\\n",
       "0                                              0.023994           ...   \n",
       "1                                              0.023994           ...   \n",
       "2                                              0.023994           ...   \n",
       "3                                              0.023994           ...   \n",
       "4                                              0.023994           ...   \n",
       "...                                                 ...           ...   \n",
       "1613                                           0.000000           ...   \n",
       "1614                                           0.037006           ...   \n",
       "1615                                           0.018646           ...   \n",
       "1616                                           0.000000           ...   \n",
       "1617                                           0.000000           ...   \n",
       "\n",
       "      OxidationStates|std_dev oxidation state   MP_Eg  OQMD_Eg  AFLOW_Eg  \\\n",
       "0                                         0.0  2.4881    2.085    2.5251   \n",
       "1                                         0.0  1.0119    0.000    0.9784   \n",
       "2                                         0.0  0.5752    0.000    0.1534   \n",
       "3                                         0.0  2.7785    0.000    2.4528   \n",
       "4                                         0.0  3.3395    0.000    3.3412   \n",
       "...                                       ...     ...      ...       ...   \n",
       "1613                                      0.0  4.7325    0.000    0.0000   \n",
       "1614                                      0.0  2.0461    0.000    0.0000   \n",
       "1615                                      0.0  3.2147    0.000    0.0000   \n",
       "1616                                      0.0  5.9434    0.000    0.0000   \n",
       "1617                                      0.0  6.5561    0.000    0.0000   \n",
       "\n",
       "      AFLOW-fitted_Eg  AFLOWML_Eg  JARVIS-TBMBJ_Eg  JARVIS-OPT_Eg  Exp_Eg  \\\n",
       "0             4.31683       2.490           3.0448         1.9604     0.0   \n",
       "1             2.23188       0.997           2.2888         0.8982     0.0   \n",
       "2             1.11978       0.000           0.6148         0.1655     0.0   \n",
       "3             4.21937       3.355           3.3186         2.7427     0.0   \n",
       "4             5.41694       3.166           4.7622         3.7645     0.0   \n",
       "...               ...         ...              ...            ...     ...   \n",
       "1613          0.00000       4.468           0.0000         0.0000     0.0   \n",
       "1614          0.00000       1.346           0.0000         0.0000     0.0   \n",
       "1615          0.00000       2.872           0.0000         0.0000     0.0   \n",
       "1616          0.00000       5.359           0.0000         0.0000     0.0   \n",
       "1617          0.00000       6.344           0.0000         0.0000     0.0   \n",
       "\n",
       "      spillage  \n",
       "0        0.000  \n",
       "1        0.000  \n",
       "2        1.318  \n",
       "3        0.000  \n",
       "4        0.000  \n",
       "...        ...  \n",
       "1613     0.000  \n",
       "1614     0.000  \n",
       "1615     0.000  \n",
       "1616     0.000  \n",
       "1617     0.000  \n",
       "\n",
       "[1618 rows x 3482 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData   = pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"trainingData.pkl\")\n",
    "trainingTarget= pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"trainingTarget.pkl\")\n",
    "testSet       = pd.read_pickle(data_dir / InsertApproach / \"processed\" / \"testSet.pkl\")\n",
    "\n",
    "trainingData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "Below we define the algorithm to use and its abbreviation. Parameters that are optional to tune are the parameters to the algorithms, with the default value as their optimised value. Another parameter to tune is how many cross-validations one wants to iterate through for the analysis. In addition, one has to find the best features for a new algorithm which will be added further down in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertAlgorithms    = [RandomForestClassifier    (max_depth = 5, random_state=random_state),\\\n",
    "                 GradientBoostingClassifier(max_depth = 2, random_state=random_state)]\n",
    "InsertAbbreviations = [\"RF\", \"GB\"]\n",
    "InsertprettyNames   = [\"Random Forest\", \"Gradient Boost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis\n",
    "\n",
    "\n",
    "## How do we evaluate the model?\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. \n",
    "\n",
    "### k-fold cross-validation\n",
    "\n",
    "In k-fold cross-validation, the sample is partioned into k equal sized subsamples. Of the k samples, a single sample is used as validation set while the remaining k-1 samples are used as training data. The process is then repeated k-times, such that each of the k-th subsample is used as validation set exactly one time. Therefore, all observations are used for both training and validation, and each observation is used for validation exactly once. The k results from the folds can then be averaged to produce an estimate.\n",
    "\n",
    "### Stratified k-fold cross-validation\n",
    "\n",
    "In stratified k-fold cross validation, the fold that is selected contains roughly the same proportions of existing class labels. \n",
    "\n",
    "### n-repeated stratified k-fold cross-validation\n",
    "\n",
    "In n-repeated stratified k-fold cross-validation, the stratified k-fold cross-validation is repeated n times, which yields n random partitions of the original sample. The n results can be averaged to produce a single estimation. \n",
    "\n",
    "## Sample size\n",
    "To not discrimate a class, we make sure that each class is equally represented in the subsamples. Underneath shows a brief overview of the different methods involved to deal with this challenge.\n",
    "\n",
    "### Random oversampling of minority class\n",
    "\n",
    "Random oversampling can be achived by randomly duplicating examples from the minority class and adding them to the training dataset. \n",
    "\n",
    "The approach can be effective to algorithms that are vulnerable to a skewed dsitribution, however, it can also affect algorithms to overfit the minority class. \n",
    "\n",
    "### Random Undersampling of majority class\n",
    "\n",
    "Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset. \n",
    "\n",
    "This can prove problematic, since the loss of data can make the decision boundary between minority and majority instances harder to learn. Additionally, there is a chance that the model might loose valuable information. \n",
    "\n",
    "### Both oversampling and undersampling\n",
    "\n",
    "A third option might be to combine the two of them. \n",
    "\n",
    "\n",
    "## Optimal hyperparameters search\n",
    "\n",
    "In this section we will find the optimal parameters used for the various algorithms. We will use imblearn's Pipeline and its implemented samplers, such as SMOTE and RandomUnderSampler. The advantage of using imblearn instead of sklearn, is that sklearn's pipeline will fit the samplers to the validation data as well, while imblearn only fit the resamplers to the training data. We store the best estimators and use them again under this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best params for: RF \n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "Finding best params for: RF under\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "Finding best params for: RF over\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "Finding best params for: RF both\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [12:32, 752.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best params for: GB \n",
      "Fitting 10 folds for each of 36288 candidates, totalling 362880 fits\n"
     ]
    }
   ],
   "source": [
    "numberRuns=1\n",
    "numberSplits = 10\n",
    "\n",
    "includeSampleMethods = [\"\", \"under\", \"over\", \"both\"]\n",
    "\n",
    "Abbreviations = []\n",
    "prettyNames   = []\n",
    "Algorithms = []\n",
    "\n",
    "rskfold = RepeatedStratifiedKFold(n_splits=numberSplits, n_repeats=numberRuns, random_state=random_state)\n",
    "\n",
    "ModelsBestParams = pd.Series({}, dtype=\"string\")\n",
    "\n",
    "for i, algorithm in tqdm(enumerate(InsertAlgorithms)):\n",
    "    for method in includeSampleMethods:\n",
    "        print(\"Finding best params for: {}\".format(InsertAbbreviations[i] + \" \" + method))\n",
    "        bestEstimator, ModelsBestParams[InsertAbbreviations[i] + \" \" + method] = train_model.applyGridSearch(\n",
    "                                                                             X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                                                             y = trainingTarget.values.reshape(-1,),\n",
    "                                                                        model = algorithm, \n",
    "                                                                           cv = rskfold, \n",
    "                                                                 sampleMethod = method)\n",
    "        Abbreviations.append(InsertAbbreviations[i] + \" \" + method)\n",
    "        prettyNames.append(InsertAbbreviations[i] + \" \" + method)\n",
    "        Algorithms.append(bestEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ModelsBestParams[\"RF \"].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
    "          fontsize=16)\n",
    "\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0, 402)\n",
    "ax.set_ylim(0.73, 1)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(ModelsBestParams[\"RF \"].cv_results_['param_model__n_estimators'].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), ['g', 'k']):\n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score,\n",
    "                (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the different supervised models\n",
    "Under follows the general model runSupervisedModel that takes the as parameter which model to run and returns nice statistics formatted as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SupervisedModels = pd.Series({}, dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, algorithm in enumerate(Algorithms): \n",
    "    print(\"Current training algorithm: {}\".format(prettyNames[i]))\n",
    "    SupervisedModels[Abbreviations[i]] = (\n",
    "        train_model.runSupervisedModel(classifier  = algorithm, \n",
    "                                     X = trainingData.drop([\"material_id\", \"full_formula\"], axis=1), \n",
    "                                     y = trainingTarget.values.reshape(-1,),\n",
    "                                     k = numberSplits,\n",
    "                                     n = numberRuns,\n",
    "                      resamplingMethod = \"under\",\n",
    "                     featureImportance = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the cross-validated trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_accuracy(SupervisedModels, prettyNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is calculated as a function difference of the $100$ models in the purpose of visalizing how much the models deviate from each other.\n",
    "\n",
    "## Interpreting important features used by the models\n",
    "\n",
    "Which features are the most important in predicting to give a label $0$ or $1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def plot_important_features(models, names):\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text='Features used in model (Nruns = {})'.format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title=\"Number times\"),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        fig.add_traces(go.Bar(name=names[i], x=trainingData.columns.values, y=model['importantKeys']))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text=\"Feature Importance for the 100th iteration\".format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title='Relative importance'),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        fig.add_traces(go.Bar(name=names[i], x=trainingData.columns.values, y=model['relativeImportance']))\n",
    "\n",
    "    fig.show()\n",
    "\"\"\"\n",
    "#visualize.plot_important_features(SupervisedModels, prettyNames, \n",
    "#                        X=trainingData.drop([\"material_id\", \"full_formula\"], axis=1),\n",
    "#                       k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_important_features_restricted_domain(SupervisedModels, prettyNames, trainingData, k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_metrics(models, names, data, abbreviations=[]):\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text=\"False positives (Nruns = {})\".format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title='Counts'),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        fig.add_traces(go.Bar(name=names[i], \n",
    "                            x=data['full_formula'][model['falsePositives'] > 0],\n",
    "                            y=model['falsePositives'][model['falsePositives'] > 0]))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig = go.Figure( \n",
    "            layout = go.Layout (\n",
    "                title=go.layout.Title(text=\"False negatives (Nruns = {})\".format(numberRuns*numberSplits)),\n",
    "                yaxis=dict(title='Counts'),\n",
    "                barmode='group'\n",
    "            )\n",
    "        )\n",
    "    for i, model in enumerate(models):\n",
    "        fig.add_traces(go.Bar(name=names[i], \n",
    "                                x=data['full_formula'][model['falseNegatives'] > 0],\n",
    "                                y=model['falseNegatives'][model['falseNegatives'] > 0]))\n",
    "\n",
    "    fig.show()\n",
    "plot_confusion_metrics(SupervisedModels, prettyNames, trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.plot_confusion_matrixQT(SupervisedModels, trainingTarget, trainingData, names=prettyNames, k = numberSplits, n = numberRuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize.confusion_matrixQT(SupervisedModels, trainingTarget, prettyNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting solid-state qubit candidates\n",
    "\n",
    "It is time to make the prediction based on the best estimators and features possible. We have chosen to choose the features that have been deemed important by sklearn at least 50 percent of the cross validation runs as important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary                 = pd.DataFrame({}, dtype=\"string\")\n",
    "Summary[\"material_id\"]  = testSet[\"material_id\"]\n",
    "Summary[\"full_formula\"] = testSet[\"full_formula\"]\n",
    "Summary[\"pretty_formula\"] = testSet[\"pretty_formula\"]\n",
    "\n",
    "PredictedCandidates = pd.Series({}, dtype=\"string\")\n",
    "\n",
    "threshold = numberSplits*numberRuns/2 #50% when equal\n",
    "trainSet = trainingData.drop([\"material_id\", \"full_formula\"], axis=1)\n",
    "testData = testSet.drop([\"pretty_formula\", \"candidate\", \"full_formula\", \"material_id\"], axis=1)\n",
    "fittedAlgorithms = [] \n",
    "\n",
    "for i, algorithm in tqdm(enumerate(Algorithms)):\n",
    "    \n",
    "    fittedAlgorithm = train_model.fitAlgorithm(algorithm, \n",
    "                                    trainingData   = trainSet[trainSet.columns[SupervisedModels[Abbreviations[i]][\"importantKeys\"]>threshold]],\\\n",
    "                                    trainingTarget = trainingTarget.values.reshape(-1,),)\n",
    "    \n",
    "    fittedAlgorithms.append(fittedAlgorithm)\n",
    "    \n",
    "    PredictedCandidates[Abbreviations[i]],\\\n",
    "    PredictedCandidates[Abbreviations[i]+\" Prob\"] = predict_model.runPredictions(fittedAlgorithm,\\\n",
    "                                                        testData = testData[testData.columns[SupervisedModels[Abbreviations[i]][\"importantKeys\"]>threshold]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abbreviation in Abbreviations:\n",
    "    Summary[abbreviation]            = PredictedCandidates[abbreviation]\n",
    "    Summary[abbreviation + \"Prob\"]       = PredictedCandidates[abbreviation + \"Prob\"]\n",
    "    print(\"{} predict the number of candidates as: {}\".format(abbreviation, int(np.sum(PredictedCandidates[abbreviation]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the summary and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fitted_algorithm in tqdm(enumerate(fittedAlgorithms)):\n",
    "    file_path = Path(models_dir / InsertApproach / \"trained-models\" / Path(prettyNames[i] + \".pkl\"))\n",
    "    with file_path.open(\"wb\") as fp:\n",
    "        pickle.dump(fitted_algorithm, fp)\n",
    "        \n",
    "\n",
    "Summary.to_pickle(models_dir / InsertApproach / \"summary\" / \"summary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
